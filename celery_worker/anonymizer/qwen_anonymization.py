#TODO: Add text preprocessing after mappings for case normalization

#TODO: –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø—Ä–æ–º–ø—Ç—ã –ê–ª–µ–∫—Å—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞—Ä—Ç—ã + —Å–∞–º–º–∞—Ä–∏

#TODO: Go through multiple rounds of prompts to create the mappings. Round 1: prompt with existing mappings and update it if new entities have been identified, Round 2: anonymize text algorithmically, Round 3: depending on the end result - create another mapping or compare the already existing mapping to what the llm has produced
import os
import requests
from tokenCounter import count_tokens
import re
from pydantic import BaseModel
import json
import whisper, torch

OLLAMA_URL = os.getenv("OLLAMA_HOST", "http://localhost:11434")

def remove_tagged_text(text:str, tag:str) -> str:
    """
    Remove parts of text enclosed in a specific tag.
    """
    pattern = re.compile(r"<" + tag + r">.*?</" + tag + r">", re.DOTALL)
    return re.sub(pattern, "", text)

def get_anonymization_mapping(text: str, model_name: str) -> dict[str, str] | str:
    """
    Generates anonymization mapping from the provided text using LLM.
    Returns a dict with mappings or an error string.
    """
    prompt = f"""–ó–ê–î–ê–ß–ê: –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ä—Ç—ã –∑–∞–º–µ–Ω –¥–ª—è –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –±–∏–∑–Ω–µ—Å-–≤—Å—Ç—Ä–µ—á–∏

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –≤—ã—è–≤–∏—Ç—å –í–°–ï —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏–π.

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –ü–†–ò–ù–¶–ò–ü–´:
1. –ü–û–õ–ù–û–¢–ê: –ù–∞–π–¥–∏ –∫–∞–∂–¥–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –≤–∫–ª—é—á–∞—è –∫–æ—Å–≤–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏
2. –ö–û–ù–°–ò–°–¢–ï–ù–¢–ù–û–°–¢–¨: –û–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ = –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∑–∞–º–µ–Ω—ã –ø–æ –≤—Å–µ–º—É —Ç–µ–∫—Å—Ç—É
3. –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨: –ü—Ä–∏ —Å–æ–º–Ω–µ–Ω–∏—è—Ö –≤—ã–±–∏—Ä–∞–π –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—é

–ö–ê–¢–ï–ì–û–†–ò–ò –î–õ–Ø –ü–û–ò–°–ö–ê (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ):

üî¥ –ö–û–ú–ü–ê–ù–ò–ò –ò –ü–†–û–î–£–ö–¢–´ (–í–´–°–û–ö–ò–ô –ü–†–ò–û–†–ò–¢–ï–¢):
- –ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–π (–≤–∫–ª—é—á–∞—è —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è, –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã)  
- –ë—Ä–µ–Ω–¥—ã –∏ —Ç–æ—Ä–≥–æ–≤—ã–µ –º–∞—Ä–∫–∏
- –ù–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –∏ —Å–µ—Ä–≤–∏—Å–æ–≤
- –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∫–æ–¥–æ–≤—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤
- –ù–∞–∑–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º –∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º

üî¥ –ü–ï–†–°–û–ù–ê–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï (–í–´–°–û–ö–ò–ô –ü–†–ò–û–†–ò–¢–ï–¢):
- –§–ò–û —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ (–ø–æ–ª–Ω—ã–µ –∏ —á–∞—Å—Ç–∏—á–Ω—ã–µ)
- –î–æ–ª–∂–Ω–æ—Å—Ç–∏ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫–æ–º–ø–∞–Ω–∏–π
- Email –∞–¥—Ä–µ—Å–∞ –∏ —Ç–µ–ª–µ—Ñ–æ–Ω—ã
- –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ª–æ–≥–∏–Ω—ã –∏ –∞–∫–∫–∞—É–Ω—Ç—ã

üî¥ –ì–ï–û–ì–†–ê–§–ò–Ø:
- –ì–æ—Ä–æ–¥–∞, —Ä–µ–≥–∏–æ–Ω—ã, —Å—Ç—Ä–∞–Ω—ã
- –ê–¥—Ä–µ—Å–∞ –æ—Ñ–∏—Å–æ–≤ –∏ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π
- –ù–∞–∑–≤–∞–Ω–∏—è –ª–æ–∫–∞—Ü–∏–π –∏ –ø–ª–æ—â–∞–¥–æ–∫

üî¥ –¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø (–í–´–°–û–ö–ò–ô –ü–†–ò–û–†–ò–¢–ï–¢):
- –ú–æ–¥–µ–ª–∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –∏ —Å–µ—Ä–∏–π–Ω—ã–µ –Ω–æ–º–µ—Ä–∞
- IP-–∞–¥—Ä–µ—Å–∞, –¥–æ–º–µ–Ω—ã, URL
- –í–µ—Ä—Å–∏–∏ –ü–û –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏

üî¥ –§–ò–ù–ê–ù–°–´:
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å—É–º–º—ã –∏ –±—é–¥–∂–µ—Ç—ã
- –ù–æ–º–µ—Ä–∞ –¥–æ–≥–æ–≤–æ—Ä–æ–≤
- –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ —É—Å–ª–æ–≤–∏—è

üî¥ –í–†–ï–ú–ï–ù–ù–´–ï –î–ê–ù–ù–´–ï:
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞—Ç—ã (–æ—Å—Ç–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ: "–Ω–∞ –ø—Ä–æ—à–ª–æ–π –Ω–µ–¥–µ–ª–µ")
- –°—Ä–æ–∫–∏ –ø—Ä–æ–µ–∫—Ç–æ–≤ –∏ –¥–µ–¥–ª–∞–π–Ω—ã

–°–ü–ï–¶–ò–ê–õ–¨–ù–´–ï –ò–ù–°–¢–†–£–ö–¶–ò–ò –î–õ–Ø –ê–í–¢–û–¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–ò:

‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï –ù–ê –û–®–ò–ë–ö–ò –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø:
- –ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–π –º–æ–≥—É—Ç –±—ã—Ç—å –∏—Å–∫–∞–∂–µ–Ω—ã: "–ú–∞–π–∫—Ä–æ—Å–æ—Ñ—Ç", "–ì—É–≥–ª", "–°–±–µ—Ä–±–∞–Ω–∫"
- –ü—Ä–æ–¥—É–∫—Ç—ã –º–æ–≥—É—Ç –∑–≤—É—á–∞—Ç—å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ: "–û—Ñ–∏—Å 365", "–í–∏–Ω–¥–æ–≤—Å", "–ê–Ω–¥—Ä–æ–∏–¥"  
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–º–∏
- –ò–º–µ–Ω–∞ –ª—é–¥–µ–π —á–∞—Å—Ç–æ —Ä–∞—Å–ø–æ–∑–Ω–∞—é—Ç—Å—è –Ω–µ–≤–µ—Ä–Ω–æ

–§–û–†–ú–ê–¢ –ó–ê–ú–ï–ù:
- –ò—Å–ø–æ–ª—å–∑—É–π —á–µ—Ç–∫—É—é —Å–∏—Å—Ç–µ–º—É: –ö–û–ú–ü–ê–ù–ò–Ø_1, –ü–†–û–î–£–ö–¢_1, –£–ß–ê–°–¢–ù–ò–ö_1
- –°–æ—Ö—Ä–∞–Ω—è–π —á–∏—Å–ª–æ–≤—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ —Ä–∞–º–∫–∞—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
- –ù–ï —É–∫–∞–∑—ã–≤–∞–π —Ç–∏–ø –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –∑–∞–º–µ–Ω–µ (–ù–ï "–ë–∞–Ω–∫_1", –∞ "–ö–û–ú–ü–ê–ù–ò–Ø_1")

–§–û–†–ú–ê–¢ –í–´–í–û–î–ê:

=== –ö–ê–†–¢–ê –ó–ê–ú–ï–ù ===

–ü–ï–†–°–û–ù–ê–õ–¨–ù–´–ï_–î–ê–ù–ù–´–ï:
[–ò—Å—Ö–æ–¥–Ω–æ–µ] ‚Üí [–ó–∞–º–µ–Ω–∞]
–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ ‚Üí –£–ß–ê–°–¢–ù–ò–ö_1  
–ú–∞—Ä–∏—è –°–∏–¥–æ—Ä–æ–≤–∞ ‚Üí –£–ß–ê–°–¢–ù–ò–ö_2
ivan.petrov@company.com ‚Üí EMAIL_1

–ö–û–ú–ü–ê–ù–ò–ò_–ò_–ü–†–û–î–£–ö–¢–´:
[–ò—Å—Ö–æ–¥–Ω–æ–µ] ‚Üí [–ó–∞–º–µ–Ω–∞]
Microsoft ‚Üí –ö–û–ú–ü–ê–ù–ò–Ø_1
Office 365 ‚Üí –ü–†–û–î–£–ö–¢_1
Windows Server ‚Üí –ü–†–û–î–£–ö–¢_2

–ì–ï–û–ì–†–ê–§–ò–Ø:
[–ò—Å—Ö–æ–¥–Ω–æ–µ] ‚Üí [–ó–∞–º–µ–Ω–∞]
–ú–æ—Å–∫–≤–∞ ‚Üí –ì–û–†–û–î_1
–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥ ‚Üí –ì–û–†–û–î_2

–¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø_–ò–ù–§–û–†–ú–ê–¶–ò–Ø:
[–ò—Å—Ö–æ–¥–Ω–æ–µ] ‚Üí [–ó–∞–º–µ–Ω–∞]
Dell R740 ‚Üí –û–ë–û–†–£–î–û–í–ê–ù–ò–ï_1
192.168.1.1 ‚Üí IP_–ê–î–†–ï–°_1

–§–ò–ù–ê–ù–°–´:
[–ò—Å—Ö–æ–¥–Ω–æ–µ] ‚Üí [–ó–∞–º–µ–Ω–∞]
1500000 —Ä—É–±–ª–µ–π ‚Üí –°–£–ú–ú–ê_1
–î–æ–≥–æ–≤–æ—Ä ‚Ññ12/2024 ‚Üí –î–û–ì–û–í–û–†_1

–í–†–ï–ú–ï–ù–ù–´–ï_–î–ê–ù–ù–´–ï:
[–ò—Å—Ö–æ–¥–Ω–æ–µ] ‚Üí [–ó–∞–º–µ–Ω–∞]
15 –º–∞—Ä—Ç–∞ 2024 ‚Üí –î–ê–¢–ê_1
–∫ –∫–æ–Ω—Ü—É –∫–≤–∞—Ä—Ç–∞–ª–∞ ‚Üí –°–†–û–ö_1

=== –ö–û–ù–ï–¶ –ö–ê–†–¢–´ –ó–ê–ú–ï–ù ===

–ö–û–ù–¢–†–û–õ–¨ –ö–ê–ß–ï–°–¢–í–ê:
‚úÖ –ü—Ä–æ–≤–µ—Ä—å –∫–∞–∂–¥—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –¥–≤–∞–∂–¥—ã
‚úÖ –£–±–µ–¥–∏—Å—å, —á—Ç–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∑–∞–º–µ–Ω—ã
‚úÖ –ù–∞–π–¥–∏ –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π (—Å–æ–∫—Ä–∞—â–µ–Ω–∏—è, –æ—à–∏–±–∫–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏)
‚úÖ –û–±—Ä–∞—Ç–∏ –æ—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –±—Ä–µ–Ω–¥—ã –∏ –ø—Ä–æ–¥—É–∫—Ç—ã - –∏—Ö –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç —á–∞—â–µ –≤—Å–µ–≥–æ

–¢–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:

{text}
"""


    payload = {
        "model": model_name,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.1,
            "top_p": 0.85,
            "repeat_penalty": 1.15,
            "num_predict": 3500,
            "num_ctx": min(count_tokens(prompt) + 3000, 32768),
        },
        "think": False
    }

    try:
        print("\n\n=====STARTING MAPPING GENERATION======\n")
        response = requests.post(f"{OLLAMA_URL}/api/generate", json=payload)
        response.raise_for_status()

        response_text = response.json().get("response", "").strip()

        if not response_text:
            return "[ERROR]: Empty response from model."
        
        print("\n======MAPPING GENERATION RESPONSE======\n")
        print(response_text)
        print("\n\n\n")

        print("MAPPING SAVING IN PROGRESS....\n")
        safe_model = re.sub(r'[^\w.-]+', '_', model_name)
        filename = f"tests/anonymizer_tests/qwen/{safe_model}_mappings(CLAUDE_PROMPTS).txt"
        with open(filename, "w+", encoding="utf-8", newline="") as file:
         file.write(f"–ú–û–î–ï–õ–¨: {model_name}\n\n")
         file.write("–û–¢–í–ï–¢:\n")
         file.write(response_text)
         file.write("\n")


        print("\n!DONE SAVING MAPPINGS!\n")
        return response_text
    except Exception as e:
        return f"[ERROR]: {e}"

def anonymize_transcript(text: str, mappings: str, model_name: str = "qwen3:30b"):
    prompt = f"""–ó–ê–î–ê–ß–ê: –ü—Ä–∏–º–µ–Ω–∏—Ç—å –∫–∞—Ä—Ç—É –∑–∞–º–µ–Ω –∏ –æ—á–∏—Å—Ç–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å —É–º–µ—Ä–µ–Ω–Ω—ã–º —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ–º

–í–ê–ñ–ù–û: –¶–µ–ª—å - —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –Ω–∞ 40-50% (–Ω–µ 70%!), —Å–æ—Ö—Ä–∞–Ω–∏–≤ –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç.

–≠–¢–ê–ü 1 - –ê–ù–û–ù–ò–ú–ò–ó–ê–¶–ò–Ø:

–°–¢–†–û–ì–ò–ï –ü–†–ê–í–ò–õ–ê –ó–ê–ú–ï–ù–´:
1. –ù–∞–π–¥–∏ –≤ –∫–∞—Ä—Ç–µ –∑–∞–º–µ–Ω –ö–ê–ñ–î–£–Æ —Å—Ç—Ä–æ–∫—É —Ñ–æ—Ä–º–∞—Ç–∞: [–ò—Å—Ö–æ–¥–Ω–æ–µ] ‚Üí [–ó–∞–º–µ–Ω–∞]
2. –ó–∞–º–µ–Ω–∏ –í–°–ï –≤—Ö–æ–∂–¥–µ–Ω–∏—è [–ò—Å—Ö–æ–¥–Ω–æ–≥–æ] –Ω–∞ [–ó–∞–º–µ–Ω–∞] –ø–æ –≤—Å–µ–º—É —Ç–µ–∫—Å—Ç—É
3. –£—á–∏—Ç—ã–≤–∞–π —Ä–µ–≥–∏—Å—Ç—Ä –∏ —Å–ª–æ–≤–æ—Ñ–æ—Ä–º—ã: "Microsoft" –∏ "–º–∞–π–∫—Ä–æ—Å–æ—Ñ—Ç" = –ö–û–ú–ü–ê–ù–ò–Ø_1
4. –°–æ—Ö—Ä–∞–Ω—è–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: —Å–º—ã—Å–ª —Ñ—Ä–∞–∑ –Ω–µ –¥–æ–ª–∂–µ–Ω —Ç–µ—Ä—è—Ç—å—Å—è
5. –ü—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –≤ –∫–∞—Ä—Ç–µ - –æ—Å—Ç–∞–≤–ª—è–π –∫–∞–∫ –µ—Å—Ç—å, –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã–µ –∑–∞–º–µ–Ω—ã

–≠–¢–ê–ü 2 - –†–ê–ó–ú–ï–¢–ö–ê –£–ß–ê–°–¢–ù–ò–ö–û–í:
- –ü–µ—Ä–≤—ã–π –≥–æ–≤–æ—Ä—è—â–∏–π = –£–ß–ê–°–¢–ù–ò–ö_1  
- –í—Ç–æ—Ä–æ–π –≥–æ–≤–æ—Ä—è—â–∏–π = –£–ß–ê–°–¢–ù–ò–ö_2
- –ú–æ–¥–µ—Ä–∞—Ç–æ—Ä/–≤–µ–¥—É—â–∏–π = –ú–û–î–ï–†–ê–¢–û–† (–µ—Å–ª–∏ –µ—Å—Ç—å)
- –°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏–∞–ª–æ–≥–∞ —Å –∏–º–µ–Ω–∞–º–∏ —Ä–æ–ª–µ–π

–≠–¢–ê–ü 3 - –û–ß–ò–°–¢–ö–ê (–£–ú–ï–†–ï–ù–ù–ê–Ø):

–£–ë–†–ê–¢–¨ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û:
- –ú–µ–∂–¥–æ–º–µ—Ç—å—è: "—ç—ç—ç", "–º–º–º", "—Ö–º", "–∞–∞–∞"
- –ü–æ–≤—Ç–æ—Ä—ã: "—ç—Ç–æ —ç—Ç–æ –≤–∞–∂–Ω–æ" ‚Üí "—ç—Ç–æ –≤–∞–∂–Ω–æ" 
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ: "–º–µ–Ω—è —Å–ª—ã—à–Ω–æ?", "—Å–≤—è–∑—å –ø–ª–æ—Ö–∞—è"
- –°–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã: "–∫–æ—Ä–æ—á–µ", "—Ç–∏–ø–∞", "–∫–∞–∫ –±—ã", "–≤ –æ–±—â–µ–º-—Ç–æ"

–°–û–ö–†–ê–¢–ò–¢–¨ –û–°–¢–û–†–û–ñ–ù–û:
- "–Ø —Ö–æ—Ç–µ–ª –±—ã —Å–∫–∞–∑–∞—Ç—å, —á—Ç–æ –Ω–∞–º —Å—Ç–æ–∏—Ç —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å" ‚Üí "–ü—Ä–µ–¥–ª–∞–≥–∞—é —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å"
- "–í–æ–∑–º–æ–∂–Ω–æ, –Ω–∞–º —Å–ª–µ–¥—É–µ—Ç –ø–æ–¥—É–º–∞—Ç—å –æ —Ç–æ–º, —á—Ç–æ" ‚Üí "–°—Ç–æ–∏—Ç —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å"
- "–ï—Å–ª–∏ —è –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–Ω–∏–º–∞—é, —Ç–æ –ø–æ–ª—É—á–∞–µ—Ç—Å—è" ‚Üí "–¢–æ –µ—Å—Ç—å"

–°–û–•–†–ê–ù–ò–¢–¨ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û:
- –í—Å–µ —Ä–µ—à–µ–Ω–∏—è –∏ –≤—ã–≤–æ–¥—ã
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö  
- –í–∞–∂–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã
- –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ (–≤ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ)
- –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏ –∏ –¥–µ–¥–ª–∞–π–Ω—ã

–≠–¢–ê–ü 4 - –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ò–ï:

–§–û–†–ú–ê–¢ –í–´–í–û–î–ê:

=== –ê–ù–û–ù–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –¢–†–ê–ù–°–ö–†–ò–ü–¢ ===

–£–ß–ê–°–¢–ù–ò–ö–ò:
- –£–ß–ê–°–¢–ù–ò–ö_1: [–∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ä–æ–ª—å]
- –£–ß–ê–°–¢–ù–ò–ö_2: [–∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ä–æ–ª—å]  
- –ú–û–î–ï–†–ê–¢–û–†: [–∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ä–æ–ª—å]

–û–°–ù–û–í–ù–û–ï –°–û–î–ï–†–ñ–ê–ù–ò–ï:

**[–≤—Ä–µ–º—è/—Ç–µ–º–∞]**
–£–ß–ê–°–¢–ù–ò–ö_1: [–æ—á–∏—â–µ–Ω–Ω–∞—è —Ä–µ—á—å]
–£–ß–ê–°–¢–ù–ò–ö_2: [–æ—á–∏—â–µ–Ω–Ω–∞—è —Ä–µ—á—å]

**[—Å–ª–µ–¥—É—é—â–∞—è —Ç–µ–º–∞]**
[–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞...]

–ö–õ–Æ–ß–ï–í–´–ï –†–ï–®–ï–ù–ò–Ø:
1. [—Ä–µ—à–µ–Ω–∏–µ –≤ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ]
2. [—Ä–µ—à–µ–Ω–∏–µ –≤ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ]

–î–ï–ô–°–¢–í–ò–Ø:
| –ß—Ç–æ | –ö—Ç–æ | –ö–æ–≥–¥–∞ |
|-----|-----|-------|
| [–¥–µ–π—Å—Ç–≤–∏–µ] | [—Ä–æ–ª—å] | [—Å—Ä–æ–∫] |

–í–û–ü–†–û–°–´ –ö –ü–†–û–†–ê–ë–û–¢–ö–ï:
- [–≤–æ–ø—Ä–æ—Å 1]
- [–≤–æ–ø—Ä–æ—Å 2]

=== –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò ===
–ò—Å—Ö–æ–¥–Ω–∞—è –¥–ª–∏–Ω–∞: [—Å–ª–æ–≤]
–§–∏–Ω–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: [—Å–ª–æ–≤]  
–°–æ–∫—Ä–∞—â–µ–Ω–∏–µ: [%] (—Ü–µ–ª—å: 40-50%)
–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–º–µ–Ω: [—á–∏—Å–ª–æ]

–ö–û–ù–¢–†–û–õ–¨ –ö–ê–ß–ï–°–¢–í–ê:
‚úÖ –í—Å–µ –∑–∞–º–µ–Ω—ã –∏–∑ –∫–∞—Ä—Ç—ã –ø—Ä–∏–º–µ–Ω–µ–Ω—ã
‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω —Å–º—ã—Å–ª –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç  
‚úÖ –£–±—Ä–∞–Ω—ã —à—É–º—ã, –Ω–æ –æ—Å—Ç–∞–≤–ª–µ–Ω–∞ —Å—É—Ç—å
‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏–∞–ª–æ–≥–∞ –ø–æ–Ω—è—Ç–Ω–∞

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:

–ö–ê–†–¢–ê –ó–ê–ú–ï–ù:
{mappings}

–ò–°–•–û–î–ù–´–ô –¢–†–ê–ù–°–ö–†–ò–ü–¢:
{text}
"""
    
    payload = {
        "model": model_name,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.05,
            "top_p": 0.9,
            "repeat_penalty": 1.1,
            "num_predict": 9000,
            "num_ctx": min(count_tokens(prompt) + 5000, 32768),
        },
        "think": False
    }

    try:
        print("=====STARTING TRANSCRIPT ANONYMIZATION=====")
        response = requests.post(f"{OLLAMA_URL}/api/generate", json=payload)
        response.raise_for_status()

        response_text = response.json().get("response", "").strip()

        if not response_text:
            return "[ERROR]: Empty response from model."
        
        print("\n======TRANSCRIPT ANONYMIZATION RESPONSE======\n")
        print(response_text)
        print("\n\n\n")
        
        print("ANON TRANSCRIPT SAVING IN PROGRESS....\n")
        safe_model = re.sub(r'[^\w.-]+', '_', model_name)
        filename = f"tests/anonymizer_tests/qwen/{safe_model}_anontranscript(CLAUDE_PROMPTS).txt"
        with open(filename, "w+", encoding="utf-8", newline="") as file:
         file.write(f"–ú–û–î–ï–õ–¨: {model_name}\n\n")
         file.write("–û–¢–í–ï–¢:\n")
         file.write(response_text)
         file.write("\n")

        print("!DONE!")
        return response_text
    except Exception as e:
        return f"[ERROR]: {e}"

def transcribe_meeting():
   filepath = "new_meeting.mp3"

   print(f"Saved uploaded file to: {filepath}")
   print("STARTING TRANSCRIPTION")

   print(f"\nPyTorch version: {torch.__version__}\n")
   print(f"\nCUDA version: {torch.version.cuda}\n")
   print(f"\nCUDA available: {torch.cuda.is_available()}\n")
   print(f"\ncuDNN enabled: {torch.backends.cudnn.enabled}\n")

   device = "cuda" if torch.cuda.is_available() else "cpu"
   model = whisper.load_model("large").to(device)

   result = model.transcribe(filepath, fp16 = (device == "cuda"))

   output_filename = os.path.splitext(os.path.basename(filepath))[0]
   output_path = os.path.join("transcripts", f"{output_filename}.txt")
   with open(output_path, "w+", encoding="utf-8") as file:
      file.write(result["text"])
   
   return output_path

if __name__ == "__main__":
   filepath = "transcripts/–î–∏–æ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç—ã/new_meeting.txt"

   # option = int(input("Choose file option:\n 1. –ö–æ–º–∞–Ω–¥–æ—Å17-12.txt \t 2. –ö–æ–º–∞–Ω–¥–æ—Å23-12.txt\n"))
   # if option == 2:
   #    filepath = "transcripts/–ö–æ–º–∞–Ω–¥–æ—Å23-12.txt"
   # elif option == 1:
   #    filepath = "transcripts/–ö–æ–º–∞–Ω–¥–æ—Å17-12.txt"

   print(f"\n–§–ê–ô–õ –í–´–ë–†–ê–ù: {filepath}\n")
   with open(f"{filepath}", "r", encoding="utf-8") as file:
      orginal_text = file.read()

   mapping_model_name = "qwen3:30b"

   print("\n============Starting anonymization pipeline============\n")
   anon_mapping = get_anonymization_mapping(orginal_text, mapping_model_name)

   anon_model_name = "qwen3:30b"
   anonymize_transcript(orginal_text, anon_mapping, model_name=anon_model_name)
    